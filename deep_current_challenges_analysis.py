#!/usr/bin/env python3
"""
TSV_MATOMEã‚·ã‚¹ãƒ†ãƒ ã®ç¾åœ¨ã®èª²é¡Œæ„Ÿã®æ·±åˆ»ãªå†æ¤œè¨
é‡è¦ãªä¿®æ­£å®Œäº†å¾Œã®çœŸã®èª²é¡Œã‚’å®¢è¦³çš„ã«åˆ†æ
"""
import sqlite3
import time
import subprocess
import json
from datetime import datetime

def analyze_current_state():
    """ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’åŒ…æ‹¬çš„ã«åˆ†æ"""
    
    conn = sqlite3.connect("output.db")
    cursor = conn.cursor()
    
    print("ğŸ” TSV_MATOME ç¾åœ¨ã®èª²é¡Œæ„Ÿ - æ·±åˆ»ãªå†æ¤œè¨")
    print("=" * 60)
    print(f"åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # 1. è§£æ±ºæ¸ˆã¿å•é¡Œã®ç¢ºèª
    print("\nâœ… è§£æ±ºæ¸ˆã¿é‡è¦å•é¡Œã®ç¢ºèª")
    print("-" * 40)
    
    # é‡è¤‡è¡¨ç¤ºå•é¡Œã®è§£æ±ºç¢ºèª
    cursor.execute("""
        SELECT COUNT(*) as total_count,
               COUNT(DISTINCT app_num) as unique_count
        FROM unified_trademark_search_view
        WHERE trademark_text LIKE '%ã‚½ãƒ‹ãƒ¼%'
    """)
    result = cursor.fetchone()
    if result:
        total, unique = result
        duplicate_ratio = total / unique if unique > 0 else 0
        print(f"1. é‡è¤‡è¡¨ç¤ºå•é¡Œ: {total}ä»¶/{unique}ä»¶ (å€ç‡: {duplicate_ratio:.1f})")
        if duplicate_ratio <= 1.1:
            print("   âœ… å®Œå…¨è§£æ±ºæ¸ˆã¿")
        else:
            print(f"   âŒ æœªè§£æ±º ({duplicate_ratio:.1f}å€é‡è¤‡)")
    
    # å•†å“åŒºåˆ†æ¤œç´¢ã®æ€§èƒ½ç¢ºèª
    start_time = time.time()
    try:
        result = subprocess.run(
            'python3 cli_trademark_search.py --goods-classes "09" --limit 1',
            shell=True, capture_output=True, text=True, timeout=5
        )
        search_time = time.time() - start_time
        if result.returncode == 0:
            print(f"2. å•†å“åŒºåˆ†æ¤œç´¢æ€§èƒ½: {search_time:.2f}ç§’")
            if search_time < 2:
                print("   âœ… é«˜é€ŸåŒ–å®Œäº†")
            else:
                print(f"   âš ï¸ è¦æ”¹å–„ ({search_time:.1f}ç§’)")
        else:
            print("2. å•†å“åŒºåˆ†æ¤œç´¢æ€§èƒ½: âŒ ã‚¨ãƒ©ãƒ¼")
    except subprocess.TimeoutExpired:
        print("2. å•†å“åŒºåˆ†æ¤œç´¢æ€§èƒ½: âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    
    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ç¢ºèª
    cursor.execute("""
        SELECT COUNT(*) FROM standard_char_t_art s
        WHERE s.normalized_app_num NOT IN (
            SELECT normalized_app_num FROM jiken_c_t WHERE normalized_app_num IS NOT NULL
        )
    """)
    orphaned_records = cursor.fetchone()[0]
    print(f"3. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§: å­¤ç«‹ãƒ¬ã‚³ãƒ¼ãƒ‰ {orphaned_records}ä»¶")
    if orphaned_records == 0:
        print("   âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§è‰¯å¥½")
    else:
        print(f"   âš ï¸ è¦ç¢ºèª ({orphaned_records}ä»¶)")
    
    # 2. ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½è©•ä¾¡
    print("\nğŸ“Š ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½è©•ä¾¡")
    print("-" * 40)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºã¨æœ€é©åŒ–çŠ¶æ³
    cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
    db_size = cursor.fetchone()[0] / (1024 * 1024)  # MB
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {db_size:.1f}MB")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«æ•°ã¨ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
    cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
    table_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM jiken_c_t")
    total_trademarks = cursor.fetchone()[0]
    
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {table_count}å€‹")
    print(f"ç·å•†æ¨™æ•°: {total_trademarks:,}ä»¶")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•°
    cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='index'")
    index_count = cursor.fetchone()[0]
    print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•°: {index_count}å€‹")
    
    # 3. æ©Ÿèƒ½åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ã®è©³ç´°è©•ä¾¡
    print("\nğŸ¯ æ©Ÿèƒ½åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸è©•ä¾¡")
    print("-" * 40)
    
    coverage_data = {}
    
    # åŸºæœ¬æƒ…å ±ï¼ˆ100%ã§ã‚ã‚‹ã¹ãï¼‰
    coverage_data['åŸºæœ¬æƒ…å ±'] = 100.0
    
    # å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆ
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        WHERE s.standard_char_t IS NOT NULL 
           OR iu.indct_use_t IS NOT NULL 
           OR su.search_use_t IS NOT NULL
    """)
    text_coverage = cursor.fetchone()[0] / total_trademarks * 100
    coverage_data['å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆ'] = text_coverage
    
    # æ¨©åˆ©è€…æƒ…å ±ï¼ˆç™»éŒ²å•†æ¨™ã®ã¿ï¼‰
    cursor.execute("SELECT COUNT(DISTINCT app_num) FROM reg_mapping")
    registered_count = cursor.fetchone()[0]
    
    cursor.execute("""
        SELECT COUNT(DISTINCT rm.app_num)
        FROM reg_mapping rm
        JOIN right_person_art_t rp ON rm.reg_num = rp.reg_num
        WHERE rp.right_person_name IS NOT NULL
    """)
    rights_with_holder = cursor.fetchone()[0]
    
    rights_coverage = (rights_with_holder / registered_count * 100) if registered_count > 0 else 0
    coverage_data['æ¨©åˆ©è€…æƒ…å ±'] = rights_coverage
    
    # ç”³è«‹äººæƒ…å ±
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        LEFT JOIN jiken_c_t_shutugannindairinin ap ON j.normalized_app_num = ap.shutugan_no 
        LEFT JOIN applicant_master am ON ap.shutugannindairinin_code = am.appl_cd
        LEFT JOIN applicant_mapping apm ON ap.shutugannindairinin_code = apm.applicant_code
        WHERE am.appl_name IS NOT NULL OR apm.applicant_name IS NOT NULL
    """)
    applicant_coverage = cursor.fetchone()[0] / total_trademarks * 100
    coverage_data['ç”³è«‹äººå'] = applicant_coverage
    
    # ç§°å‘¼æƒ…å ±
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        WHERE td.dsgnt IS NOT NULL AND td.dsgnt != ''
    """)
    pronunciation_coverage = cursor.fetchone()[0] / total_trademarks * 100
    coverage_data['ç§°å‘¼æƒ…å ±'] = pronunciation_coverage
    
    # é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_knd_info_art_table tknd ON j.normalized_app_num = tknd.normalized_app_num
        WHERE tknd.smlr_dsgn_group_cd IS NOT NULL AND tknd.smlr_dsgn_group_cd != ''
    """)
    similar_coverage = cursor.fetchone()[0] / total_trademarks * 100
    coverage_data['é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰'] = similar_coverage
    
    # ç”»åƒãƒ‡ãƒ¼ã‚¿
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_sample ts ON j.normalized_app_num = ts.normalized_app_num
        WHERE ts.image_data IS NOT NULL
    """)
    image_coverage = cursor.fetchone()[0] / total_trademarks * 100
    coverage_data['ç”»åƒãƒ‡ãƒ¼ã‚¿'] = image_coverage
    
    # ã‚«ãƒãƒ¬ãƒƒã‚¸è©•ä¾¡
    for feature, coverage in coverage_data.items():
        status = "âœ… å„ªç§€" if coverage >= 95 else "âš ï¸ æ”¹å–„å¯èƒ½" if coverage >= 80 else "âŒ è¦æ”¹å–„"
        print(f"{feature}: {coverage:.1f}% {status}")
    
    # 4. å›½éš›å•†æ¨™ã®ç¾çŠ¶è©•ä¾¡
    print("\nğŸŒ å›½éš›å•†æ¨™æ©Ÿèƒ½ã®è©•ä¾¡")
    print("-" * 40)
    
    cursor.execute("SELECT COUNT(*) FROM intl_trademark_registration")
    intl_total = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM intl_trademark_text WHERE t_dtl_explntn IS NOT NULL")
    intl_with_text = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM intl_trademark_holder WHERE holder_name IS NOT NULL")
    intl_with_holder = cursor.fetchone()[0]
    
    if intl_total > 0:
        intl_text_rate = intl_with_text / intl_total * 100
        intl_holder_rate = intl_with_holder / intl_total * 100
        
        print(f"å›½éš›å•†æ¨™ç·æ•°: {intl_total:,}ä»¶")
        print(f"ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±: {intl_text_rate:.1f}%")
        print(f"æ¨©åˆ©è€…æƒ…å ±: {intl_holder_rate:.1f}%")
        
        # å›½éš›å•†æ¨™æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        try:
            result = subprocess.run(
                'python3 cli_trademark_search.py --international --goods-classes "42" --limit 1',
                shell=True, capture_output=True, text=True, timeout=5
            )
            intl_search_time = time.time() - start_time
            if result.returncode == 0:
                print(f"å›½éš›å•†æ¨™æ¤œç´¢æ€§èƒ½: {intl_search_time:.2f}ç§’ âœ…")
            else:
                print("å›½éš›å•†æ¨™æ¤œç´¢æ€§èƒ½: âŒ ã‚¨ãƒ©ãƒ¼")
        except subprocess.TimeoutExpired:
            print("å›½éš›å•†æ¨™æ¤œç´¢æ€§èƒ½: âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    
    # 5. ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ã®è©•ä¾¡
    print("\nğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£è©•ä¾¡")
    print("-" * 40)
    
    # æ¤œç´¢é€Ÿåº¦ãƒ†ã‚¹ãƒˆ
    search_tests = [
        ("å‡ºé¡˜ç•ªå·æ¤œç´¢", 'python3 cli_trademark_search.py --app-num "2020138119" --limit 1'),
        ("å•†æ¨™åæ¤œç´¢", 'python3 cli_trademark_search.py --mark-text "ã‚½ãƒ‹ãƒ¼" --limit 1'),
        ("é¡ä¼¼ç¾¤æ¤œç´¢", 'python3 cli_trademark_search.py --similar-group-codes "11C01" --limit 1'),
        ("è¤‡åˆæ¤œç´¢", 'python3 cli_trademark_search.py --mark-text "é›»æ°—" --goods-classes "09" --limit 1'),
    ]
    
    search_performance = {}
    for test_name, command in search_tests:
        start_time = time.time()
        try:
            result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=10)
            elapsed = time.time() - start_time
            if result.returncode == 0:
                search_performance[test_name] = elapsed
                status = "âœ… é«˜é€Ÿ" if elapsed < 1 else "âš ï¸ æ™®é€š" if elapsed < 3 else "âŒ ä½é€Ÿ"
                print(f"{test_name}: {elapsed:.2f}ç§’ {status}")
            else:
                print(f"{test_name}: âŒ ã‚¨ãƒ©ãƒ¼")
        except subprocess.TimeoutExpired:
            print(f"{test_name}: âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    
    # 6. ç¾åœ¨ã®çœŸã®èª²é¡Œç‰¹å®š
    print("\nğŸ¯ ç¾åœ¨ã®çœŸã®èª²é¡Œç‰¹å®š")
    print("-" * 40)
    
    issues = []
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª²é¡Œ
    avg_search_time = sum(search_performance.values()) / len(search_performance) if search_performance else 0
    if avg_search_time > 2:
        issues.append(("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", f"å¹³å‡æ¤œç´¢æ™‚é–“{avg_search_time:.1f}ç§’", "medium"))
    
    # ãƒ‡ãƒ¼ã‚¿èª²é¡Œ
    if coverage_data.get('ç”³è«‹äººå', 0) < 50:
        issues.append(("ç”³è«‹äººæƒ…å ±", f"ã‚«ãƒãƒ¬ãƒƒã‚¸{coverage_data['ç”³è«‹äººå']:.1f}%", "low"))
    
    if coverage_data.get('ç”»åƒãƒ‡ãƒ¼ã‚¿', 0) < 50:
        issues.append(("ç”»åƒè¡¨ç¤º", f"ã‚«ãƒãƒ¬ãƒƒã‚¸{coverage_data['ç”»åƒãƒ‡ãƒ¼ã‚¿']:.1f}%", "low"))
    
    # æ©Ÿèƒ½èª²é¡Œ
    if intl_total > 0 and intl_text_rate < 80:
        issues.append(("å›½éš›å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆ", f"æ­£è¦åŒ–æœªå¯¾å¿œ", "medium"))
    
    # çµ±åˆãƒ“ãƒ¥ãƒ¼ã®æ€§èƒ½
    start_time = time.time()
    try:
        cursor.execute("SELECT COUNT(*) FROM unified_trademark_search_view LIMIT 1")
        unified_time = time.time() - start_time
        if unified_time > 5:
            issues.append(("çµ±åˆãƒ“ãƒ¥ãƒ¼", f"å¿œç­”æ™‚é–“{unified_time:.1f}ç§’", "high"))
    except:
        issues.append(("çµ±åˆãƒ“ãƒ¥ãƒ¼", "ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼", "high"))
    
    # èª²é¡Œã®å„ªå…ˆåº¦åˆ¥æ•´ç†
    high_issues = [issue for issue in issues if issue[2] == "high"]
    medium_issues = [issue for issue in issues if issue[2] == "medium"]
    low_issues = [issue for issue in issues if issue[2] == "low"]
    
    if not issues:
        print("ğŸ‰ é‡å¤§ãªèª²é¡Œã¯ç™ºè¦‹ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")
        print("ã‚·ã‚¹ãƒ†ãƒ ã¯è‰¯å¥½ãªçŠ¶æ…‹ã§ç¨¼åƒã—ã¦ã„ã¾ã™ã€‚")
    else:
        if high_issues:
            print("ğŸ”´ é«˜å„ªå…ˆåº¦èª²é¡Œ:")
            for issue, desc, _ in high_issues:
                print(f"   - {issue}: {desc}")
        
        if medium_issues:
            print("\nğŸŸ¡ ä¸­å„ªå…ˆåº¦èª²é¡Œ:")
            for issue, desc, _ in medium_issues:
                print(f"   - {issue}: {desc}")
        
        if low_issues:
            print("\nğŸŸ¢ ä½å„ªå…ˆåº¦èª²é¡Œ:")
            for issue, desc, _ in low_issues:
                print(f"   - {issue}: {desc}")
    
    # 7. ä»Šå¾Œã®ç™ºå±•å¯èƒ½æ€§
    print("\nğŸš€ ä»Šå¾Œã®ç™ºå±•å¯èƒ½æ€§")
    print("-" * 40)
    
    development_opportunities = [
        "ğŸ” AIé§†å‹•ã®é¡ä¼¼å•†æ¨™æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³",
        "ğŸ“Š å•†æ¨™åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¿½åŠ ",
        "ğŸŒ Webã‚µãƒ¼ãƒ“ã‚¹åŒ–ã¨APIæä¾›",
        "ğŸ”„ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ",
        "ğŸ“± ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œã‚¤ãƒ³ã‚¿ãƒ¼face",
        "ğŸ¤– è‡ªå‹•åˆ†é¡ãƒ»ã‚¿ã‚°ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ",
        "ğŸ“ˆ å•†æ¨™ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†ææ©Ÿèƒ½",
        "ğŸ”— ä»–ã®çŸ¥çš„è²¡ç”£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æº"
    ]
    
    for opportunity in development_opportunities:
        print(f"   {opportunity}")
    
    # 8. ç·åˆè©•ä¾¡
    print("\n" + "=" * 60)
    print("ğŸ“‹ ç·åˆè©•ä¾¡ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    total_score = 0
    max_score = 0
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢ (40ç‚¹æº€ç‚¹)
    data_score = min(40, sum([
        coverage_data.get('åŸºæœ¬æƒ…å ±', 0) * 0.1,
        coverage_data.get('å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆ', 0) * 0.1,
        coverage_data.get('æ¨©åˆ©è€…æƒ…å ±', 0) * 0.05,
        coverage_data.get('ç”³è«‹äººå', 0) * 0.05,
        coverage_data.get('ç§°å‘¼æƒ…å ±', 0) * 0.05,
        coverage_data.get('é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰', 0) * 0.05
    ]))
    total_score += data_score
    max_score += 40
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ (30ç‚¹æº€ç‚¹)
    perf_score = 30 if avg_search_time < 1 else 20 if avg_search_time < 2 else 10 if avg_search_time < 5 else 0
    total_score += perf_score
    max_score += 30
    
    # æ©Ÿèƒ½å®Œæˆåº¦ã‚¹ã‚³ã‚¢ (30ç‚¹æº€ç‚¹)
    func_score = 30 - len(high_issues) * 10 - len(medium_issues) * 5 - len(low_issues) * 2
    func_score = max(0, func_score)
    total_score += func_score
    max_score += 30
    
    final_score = (total_score / max_score * 100) if max_score > 0 else 0
    
    print(f"ãƒ‡ãƒ¼ã‚¿å“è³ª: {data_score:.1f}/40ç‚¹")
    print(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {perf_score:.1f}/30ç‚¹")
    print(f"æ©Ÿèƒ½å®Œæˆåº¦: {func_score:.1f}/30ç‚¹")
    print(f"ç·åˆè©•ä¾¡: {final_score:.1f}/100ç‚¹")
    
    if final_score >= 90:
        grade = "S (å„ªç§€)"
    elif final_score >= 80:
        grade = "A (è‰¯å¥½)"
    elif final_score >= 70:
        grade = "B (æ™®é€š)"
    elif final_score >= 60:
        grade = "C (è¦æ”¹å–„)"
    else:
        grade = "D (å•é¡Œã‚ã‚Š)"
    
    print(f"\nğŸ† ã‚·ã‚¹ãƒ†ãƒ ç·åˆè©•ä¾¡: {grade}")
    
    conn.close()
    
    return {
        'total_score': final_score,
        'grade': grade,
        'high_issues': high_issues,
        'medium_issues': medium_issues,
        'low_issues': low_issues,
        'coverage_data': coverage_data,
        'search_performance': search_performance
    }

if __name__ == "__main__":
    result = analyze_current_state()