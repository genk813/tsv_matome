#!/usr/bin/env python3
"""
ç§°å‘¼æƒ…å ±ã¨é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ã®ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
100%ã§ãªã„ç†ç”±ã‚’è©³ç´°èª¿æŸ»
"""
import sqlite3

def analyze_coverage_gaps():
    """ç§°å‘¼ãƒ»é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ã®ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ"""
    
    conn = sqlite3.connect("output.db")
    cursor = conn.cursor()
    
    print("ğŸ” ç§°å‘¼æƒ…å ±ã¨é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ã®ã‚«ãƒãƒ¬ãƒƒã‚¸èª¿æŸ»")
    print("="*60)
    
    # 1. ç§°å‘¼æƒ…å ±ã®è©³ç´°åˆ†æ
    print("\n1. ç§°å‘¼æƒ…å ±ã®è©³ç´°åˆ†æ")
    print("-"*30)
    
    # å…¨ä½“çµ±è¨ˆ
    cursor.execute("SELECT COUNT(*) FROM jiken_c_t")
    total_trademarks = cursor.fetchone()[0]
    
    # ç§°å‘¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚‚ã®
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        WHERE td.dsgnt IS NOT NULL AND td.dsgnt != ''
    """)
    with_pronunciation = cursor.fetchone()[0]
    
    # å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹ã‚‚ã®
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        WHERE s.standard_char_t IS NOT NULL 
           OR iu.indct_use_t IS NOT NULL 
           OR su.search_use_t IS NOT NULL
    """)
    with_text = cursor.fetchone()[0]
    
    print(f"ç·å•†æ¨™æ•°: {total_trademarks:,}ä»¶")
    print(f"ç§°å‘¼ãƒ‡ãƒ¼ã‚¿ã‚ã‚Š: {with_pronunciation:,}ä»¶ ({with_pronunciation/total_trademarks*100:.1f}%)")
    print(f"å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Š: {with_text:,}ä»¶ ({with_text/total_trademarks*100:.1f}%)")
    
    # å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹ã®ã«ç§°å‘¼ãŒãªã„ã‚‚ã®
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        LEFT JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        WHERE (s.standard_char_t IS NOT NULL 
               OR iu.indct_use_t IS NOT NULL 
               OR su.search_use_t IS NOT NULL)
          AND (td.dsgnt IS NULL OR td.dsgnt = '')
    """)
    text_no_pronunciation = cursor.fetchone()[0]
    
    print(f"ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Šç§°å‘¼ãªã—: {text_no_pronunciation:,}ä»¶")
    
    # ç§°å‘¼ãŒãªã„å•†æ¨™ã®ä¾‹
    print("\nç§°å‘¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„å•†æ¨™ã®ä¾‹:")
    cursor.execute("""
        SELECT j.normalized_app_num, 
               COALESCE(s.standard_char_t, iu.indct_use_t, su.search_use_t) as text
        FROM jiken_c_t j
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        LEFT JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        WHERE (s.standard_char_t IS NOT NULL 
               OR iu.indct_use_t IS NOT NULL 
               OR su.search_use_t IS NOT NULL)
          AND (td.dsgnt IS NULL OR td.dsgnt = '')
        LIMIT 10
    """)
    
    no_pronunciation_examples = cursor.fetchall()
    for app_num, text in no_pronunciation_examples:
        if text:
            display_text = text[:50] + "..." if len(text) > 50 else text
            print(f"  {app_num}: {display_text}")
    
    print("\n2. é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ã®è©³ç´°åˆ†æ")
    print("-"*30)
    
    # é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹ã‚‚ã®
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_knd_info_art_table tknd ON j.normalized_app_num = tknd.normalized_app_num
        WHERE tknd.smlr_dsgn_group_cd IS NOT NULL AND tknd.smlr_dsgn_group_cd != ''
    """)
    with_similar_group = cursor.fetchone()[0]
    
    print(f"é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ã‚ã‚Š: {with_similar_group:,}ä»¶ ({with_similar_group/total_trademarks*100:.1f}%)")
    
    # å•†å“åŒºåˆ†ãŒã‚ã‚‹ã‚‚ã®
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN goods_class_art gca ON j.normalized_app_num = gca.normalized_app_num
        WHERE gca.goods_classes IS NOT NULL AND gca.goods_classes != ''
    """)
    with_goods_class = cursor.fetchone()[0]
    
    print(f"å•†å“åŒºåˆ†ã‚ã‚Š: {with_goods_class:,}ä»¶ ({with_goods_class/total_trademarks*100:.1f}%)")
    
    # å•†å“åŒºåˆ†ãŒã‚ã‚‹ã®ã«é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ãŒãªã„ã‚‚ã®
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN goods_class_art gca ON j.normalized_app_num = gca.normalized_app_num
        LEFT JOIN t_knd_info_art_table tknd ON j.normalized_app_num = tknd.normalized_app_num
        WHERE gca.goods_classes IS NOT NULL 
          AND (tknd.smlr_dsgn_group_cd IS NULL OR tknd.smlr_dsgn_group_cd = '')
    """)
    goods_no_similar = cursor.fetchone()[0]
    
    print(f"å•†å“åŒºåˆ†ã‚ã‚Šé¡ä¼¼ç¾¤ãªã—: {goods_no_similar:,}ä»¶")
    
    # é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ãŒãªã„å•†æ¨™ã®ä¾‹
    print("\né¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ãŒãªã„å•†æ¨™ã®ä¾‹:")
    cursor.execute("""
        SELECT j.normalized_app_num, 
               gca.goods_classes,
               COALESCE(s.standard_char_t, iu.indct_use_t, su.search_use_t) as text
        FROM jiken_c_t j
        JOIN goods_class_art gca ON j.normalized_app_num = gca.normalized_app_num
        LEFT JOIN t_knd_info_art_table tknd ON j.normalized_app_num = tknd.normalized_app_num
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        WHERE gca.goods_classes IS NOT NULL 
          AND (tknd.smlr_dsgn_group_cd IS NULL OR tknd.smlr_dsgn_group_cd = '')
        LIMIT 10
    """)
    
    no_similar_examples = cursor.fetchall()
    for app_num, goods_class, text in no_similar_examples:
        if text:
            display_text = text[:30] + "..." if len(text) > 30 else text
        else:
            display_text = "ãƒ†ã‚­ã‚¹ãƒˆãªã—"
        print(f"  {app_num}: åŒºåˆ†{goods_class} - {display_text}")
    
    print("\n3. å¹´ä»£åˆ¥åˆ†æ")
    print("-"*30)
    
    # å¹´ä»£åˆ¥ã®ç§°å‘¼ãƒ»é¡ä¼¼ç¾¤ã‚«ãƒãƒ¬ãƒƒã‚¸
    cursor.execute("""
        SELECT 
            SUBSTR(j.normalized_app_num, 1, 4) as year,
            COUNT(*) as total,
            COUNT(td.dsgnt) as with_pronunciation,
            COUNT(tknd.smlr_dsgn_group_cd) as with_similar_group
        FROM jiken_c_t j
        LEFT JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        LEFT JOIN t_knd_info_art_table tknd ON j.normalized_app_num = tknd.normalized_app_num
        WHERE SUBSTR(j.normalized_app_num, 1, 4) BETWEEN '1997' AND '2025'
        GROUP BY SUBSTR(j.normalized_app_num, 1, 4)
        ORDER BY year
    """)
    
    print("å¹´åº¦åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸:")
    print("å¹´åº¦    ç·æ•°    ç§°å‘¼ç‡  é¡ä¼¼ç¾¤ç‡")
    print("-"*35)
    
    coverage_by_year = cursor.fetchall()
    for year, total, pronunciation, similar_group in coverage_by_year:
        if total > 0:
            pron_rate = pronunciation / total * 100
            similar_rate = similar_group / total * 100
            print(f"{year}  {total:5d}  {pron_rate:5.1f}%  {similar_rate:6.1f}%")
    
    # 4. å›³å½¢å•†æ¨™ã®åˆ†æ
    print("\n4. å›³å½¢å•†æ¨™ã®åˆ†æ")
    print("-"*30)
    
    # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å•†æ¨™
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_sample ts ON j.normalized_app_num = ts.normalized_app_num
        WHERE ts.image_data IS NOT NULL
    """)
    with_image = cursor.fetchone()[0]
    
    # ç”»åƒã¯ã‚ã‚‹ãŒå•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_sample ts ON j.normalized_app_num = ts.normalized_app_num
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        WHERE ts.image_data IS NOT NULL
          AND s.standard_char_t IS NULL
          AND iu.indct_use_t IS NULL
          AND su.search_use_t IS NULL
    """)
    image_no_text = cursor.fetchone()[0]
    
    print(f"ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚ã‚Š: {with_image:,}ä»¶")
    print(f"å›³å½¢ã®ã¿(ãƒ†ã‚­ã‚¹ãƒˆãªã—): {image_no_text:,}ä»¶")
    
    # å›³å½¢å•†æ¨™ã®ç§°å‘¼çŠ¶æ³
    cursor.execute("""
        SELECT COUNT(DISTINCT j.normalized_app_num)
        FROM jiken_c_t j
        JOIN t_sample ts ON j.normalized_app_num = ts.normalized_app_num
        LEFT JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN indct_use_t_art iu ON j.normalized_app_num = iu.normalized_app_num
        LEFT JOIN search_use_t_art_table su ON j.normalized_app_num = su.normalized_app_num
        LEFT JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        WHERE ts.image_data IS NOT NULL
          AND s.standard_char_t IS NULL
          AND iu.indct_use_t IS NULL
          AND su.search_use_t IS NULL
          AND (td.dsgnt IS NULL OR td.dsgnt = '')
    """)
    figure_no_pronunciation = cursor.fetchone()[0]
    
    print(f"å›³å½¢ã®ã¿ã§ç§°å‘¼ãªã—: {figure_no_pronunciation:,}ä»¶")
    
    # 5. ç‰¹æ®Šæ–‡å­—ãƒ»è¨˜å·ã®åˆ†æ
    print("\n5. ç‰¹æ®Šæ–‡å­—ãƒ»è¨˜å·ã®åˆ†æ")
    print("-"*30)
    
    # è¨˜å·ãƒ»æ•°å­—ã‚’å«ã‚€å•†æ¨™
    cursor.execute("""
        SELECT j.normalized_app_num, s.standard_char_t
        FROM jiken_c_t j
        JOIN standard_char_t_art s ON j.normalized_app_num = s.normalized_app_num
        LEFT JOIN t_dsgnt_art td ON j.normalized_app_num = td.normalized_app_num
        WHERE s.standard_char_t LIKE '%&%'
           OR s.standard_char_t LIKE '%ï¼†%'
           OR s.standard_char_t LIKE '%â€»%'
           OR s.standard_char_t LIKE '%â˜…%'
           OR s.standard_char_t LIKE '%â™ª%'
        AND (td.dsgnt IS NULL OR td.dsgnt = '')
        LIMIT 5
    """)
    
    symbol_no_pronunciation = cursor.fetchall()
    print("è¨˜å·å«ã¿ç§°å‘¼ãªã—å•†æ¨™ã®ä¾‹:")
    for app_num, text in symbol_no_pronunciation:
        print(f"  {app_num}: {text}")
    
    conn.close()
    
    print("\n" + "="*60)
    print("ğŸ’¡ ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ100%ã§ãªã„ç†ç”±ã®çµè«–")
    print("="*60)
    print("1. ç§°å‘¼æƒ…å ±ãŒ89.2%ã®ç†ç”±:")
    print("   âœ“ å›³å½¢å•†æ¨™(ãƒ†ã‚­ã‚¹ãƒˆãªã—)ã«ã¯ç§°å‘¼ãŒä»˜ä¸ã•ã‚Œãªã„")
    print("   âœ“ è¨˜å·ãƒ»ç‰¹æ®Šæ–‡å­—ã®ã¿ã®å•†æ¨™ã«ã¯èª­ã¿æ–¹ãŒå›°é›£")
    print("   âœ“ å¤–å›½èªå•†æ¨™ã§æ—¥æœ¬èªç§°å‘¼ãŒé©åˆ‡ã§ãªã„ã‚‚ã®")
    print("   âœ“ å¤ã„ãƒ‡ãƒ¼ã‚¿(1997-2002å¹´)ã§ã®ç§°å‘¼ä»˜ä¸ã®ä¸å®Œå…¨æ€§")
    print("   âœ“ æ•°å­—ã®ã¿ã®å•†æ¨™ã«ã¯ç§°å‘¼ãŒä¸è¦")
    
    print("\n2. é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰ãŒ79.1%ã®ç†ç”±:")
    print("   âœ“ ä¸€éƒ¨ã®å•†å“ãƒ»å½¹å‹™ã‚«ãƒ†ã‚´ãƒªã§é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰æœªè¨­å®š")
    print("   âœ“ æ–°ã—ã„å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã«å¯¾ã™ã‚‹é¡ä¼¼ç¾¤æœªæ•´å‚™")
    print("   âœ“ å›½éš›å•†æ¨™ã§ã®å›½å†…é¡ä¼¼ç¾¤ã‚³ãƒ¼ãƒ‰æœªå¯¾å¿œ")
    print("   âœ“ å¤ã„ãƒ‡ãƒ¼ã‚¿ã§ã®é¡ä¼¼ç¾¤ã‚·ã‚¹ãƒ†ãƒ å¤‰æ›´ã®å½±éŸ¿")
    print("   âœ“ ç‰¹æ®Šãªå•†å“ãƒ»å½¹å‹™ã§ã®é¡ä¼¼ç¾¤åˆ†é¡ã®å›°é›£æ€§")
    
    print("\nğŸ“‹ ã“ã‚Œã‚‰ã¯ä»•æ§˜ä¸Šã®æ­£å¸¸ãªçŠ¶æ³ã§ã‚ã‚Šã€")
    print("   ã‚·ã‚¹ãƒ†ãƒ ã®ä¸å…·åˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    analyze_coverage_gaps()