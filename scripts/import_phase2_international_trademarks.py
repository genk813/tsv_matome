#!/usr/bin/env python3
"""
Phase 2: å›½éš›å•†æ¨™ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
TSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å›½éš›å•†æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ãªãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹
"""

import sqlite3
import csv
import os
import sys
from pathlib import Path
from datetime import datetime

class InternationalTrademarkImporter:
    def __init__(self, db_path="output.db", tsv_dir="tsv_data/tsv"):
        self.db_path = db_path
        self.tsv_dir = Path(tsv_dir)
        self.conn = None
        
        # TSVãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        self.tsv_files = {
            "registration": "upd_intl_t_org_org_reg_mgt_info.tsv",
            "progress": "upd_intl_t_org_prog_info.tsv", 
            "holder": "upd_intl_t_org_set_crr_nm_addr.tsv",
            "goods_services": "upd_intl_t_org_set_dsgn_gds_srvc.tsv",
            "trademark_text": "upd_intl_t_org_set_frst_indct.tsv"
        }
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆä»•æ§˜æ›¸ã‹ã‚‰æŠ½å‡ºï¼‰
        self.column_mappings = {
            "registration": [
                "add_del_id", "intl_reg_num", "intl_reg_num_updt_cnt_sign_cd", 
                "intl_reg_num_split_sign_cd", "app_num", "app_num_split_sign_cd",
                "app_date", "intl_reg_date", "effective_date", "basic_app_ctry_cd",
                "basic_app_num", "basic_app_date", "basic_reg_ctry_cd", 
                "basic_reg_num", "basic_reg_date", "rep_figure_num", "vienna_class",
                "color_claim_flg", "app_lang_cd", "second_lang_cd", "define_flg",
                "updt_year_month_day", "batch_updt_year_month_day"
            ],
            "progress": [
                "add_del_id", "intl_reg_num", "intl_reg_num_updt_cnt_sign_cd",
                "intl_reg_num_split_sign_cd", "prog_seq", "prog_cd", "prog_date",
                "prog_content", "define_flg", "updt_year_month_day", "batch_updt_year_month_day"
            ],
            "holder": [
                "add_del_id", "intl_reg_num", "intl_reg_num_updt_cnt_sign_cd",
                "intl_reg_num_split_sign_cd", "holder_seq", "holder_name",
                "holder_name_japanese", "holder_addr", "holder_addr_japanese",
                "holder_ctry_cd", "define_flg", "updt_year_month_day", "batch_updt_year_month_day"
            ],
            "goods_services": [
                "add_del_id", "intl_reg_num", "intl_reg_num_updt_cnt_sign_cd",
                "intl_reg_num_split_sign_cd", "aft_desig_year_month_day", 
                "temp_principal_reg_id_flg", "indct_seq", "goods_seq",
                "goods_class", "goods_content", "intl_reg_rec_dt", "define_flg",
                "updt_year_month_day", "batch_updt_year_month_day"
            ],
            "trademark_text": [
                "add_del_id", "intl_reg_num", "intl_reg_num_updt_cnt_sign_cd",
                "intl_reg_num_split_sign_cd", "aft_desig_year_month_day",
                "temp_principal_reg_id_flg", "indct_seq", "finl_dcsn_year_month_day",
                "trial_dcsn_year_month_day", "pri_app_gvrn_cntrcntry_cd",
                "pri_app_year_month_day", "pri_clim_cnt", "special_t_typ_flg",
                "group_cert_warranty_flg", "define_flg", "updt_year_month_day",
                "batch_updt_year_month_day", "t_dtl_explntn"
            ]
        }

    def connect_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        if not Path(self.db_path).exists():
            raise FileNotFoundError(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.db_path}")
        
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š: {self.db_path}")

    def create_tables(self):
        """ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        schema_file = Path("scripts/phase2_schema.sql")
        if not schema_file.exists():
            raise FileNotFoundError(f"ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {schema_file}")
        
        with open(schema_file, 'r', encoding='utf-8') as f:
            schema_sql = f.read()
        
        cursor = self.conn.cursor()
        cursor.executescript(schema_sql)
        self.conn.commit()
        print("âœ… Phase 2ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")

    def analyze_tsv_file(self, file_path):
        """TSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ åˆ†æ"""
        print(f"\nğŸ“„ {file_path.name} ã‚’åˆ†æä¸­...")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f, delimiter='\t')
                headers = next(reader)
                sample_rows = []
                
                # æœ€åˆã®5è¡Œã‚’å–å¾—
                for i, row in enumerate(reader):
                    if i >= 5:
                        break
                    sample_rows.append(row)
                
                print(f"   ã‚«ãƒ©ãƒ æ•°: {len(headers)}")
                print(f"   ã‚µãƒ³ãƒ—ãƒ«è¡Œæ•°: {len(sample_rows)}")
                
                # ä¸»è¦ã‚«ãƒ©ãƒ ã‚’è¡¨ç¤º
                key_columns = []
                for i, col in enumerate(headers):
                    if i < 10:  # æœ€åˆã®10ã‚«ãƒ©ãƒ 
                        key_columns.append(f"{i}: {col}")
                
                print("   ä¸»è¦ã‚«ãƒ©ãƒ :")
                for col in key_columns:
                    print(f"     {col}")
                
                return headers, sample_rows
                
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None

    def import_registration_data(self):
        """å›½éš›å•†æ¨™ç™»éŒ²ç®¡ç†æƒ…å ±ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        file_path = self.tsv_dir / self.tsv_files["registration"]
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º: {file_path}")
            return 0
        
        print(f"\nğŸ“¥ å›½éš›å•†æ¨™ç™»éŒ²ç®¡ç†æƒ…å ±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {file_path.name}")
        
        cursor = self.conn.cursor()
        imported_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f, delimiter='\t')
                headers = next(reader)
                
                # ã‚«ãƒ©ãƒ æ•°ãƒã‚§ãƒƒã‚¯
                expected_cols = len(self.column_mappings["registration"])
                actual_cols = len(headers)
                print(f"   æœŸå¾…ã‚«ãƒ©ãƒ æ•°: {expected_cols}, å®Ÿéš›: {actual_cols}")
                
                for row_num, row in enumerate(reader, 1):
                    if len(row) != actual_cols:
                        continue  # ä¸æ­£ãªè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    
                    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆNoneã§åŸ‹ã‚ã‚‹ä¸è¶³åˆ†ï¼‰
                    row_data = row + [None] * max(0, expected_cols - len(row))
                    row_data = row_data[:expected_cols]  # ä½™åˆ†ã‚’åˆ‡ã‚Šæ¨ã¦
                    
                    # INSERTæ–‡å®Ÿè¡Œ
                    placeholders = ', '.join(['?'] * expected_cols)
                    sql = f"""
                    INSERT OR REPLACE INTO intl_trademark_registration 
                    ({', '.join(self.column_mappings["registration"])})
                    VALUES ({placeholders})
                    """
                    
                    cursor.execute(sql, row_data)
                    imported_count += 1
                    
                    if imported_count % 500 == 0:
                        print(f"   é€²è¡Œä¸­: {imported_count:,} ä»¶")
                        self.conn.commit()
                
                self.conn.commit()
                print(f"âœ… ç™»éŒ²ç®¡ç†æƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {imported_count:,} ä»¶")
                
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.conn.rollback()
        
        return imported_count

    def import_progress_data(self):
        """å›½éš›å•†æ¨™é€²è¡Œæƒ…å ±ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        file_path = self.tsv_dir / self.tsv_files["progress"]
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º: {file_path}")
            return 0
        
        print(f"\nğŸ“¥ å›½éš›å•†æ¨™é€²è¡Œæƒ…å ±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {file_path.name}")
        
        cursor = self.conn.cursor()
        imported_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f, delimiter='\t')
                headers = next(reader)
                
                expected_cols = len(self.column_mappings["progress"])
                
                for row in reader:
                    if len(row) < expected_cols:
                        row_data = row + [None] * (expected_cols - len(row))
                    else:
                        row_data = row[:expected_cols]
                    
                    placeholders = ', '.join(['?'] * expected_cols)
                    sql = f"""
                    INSERT OR REPLACE INTO intl_trademark_progress 
                    ({', '.join(self.column_mappings["progress"])})
                    VALUES ({placeholders})
                    """
                    
                    cursor.execute(sql, row_data)
                    imported_count += 1
                    
                    if imported_count % 500 == 0:
                        print(f"   é€²è¡Œä¸­: {imported_count:,} ä»¶")
                        self.conn.commit()
                
                self.conn.commit()
                print(f"âœ… é€²è¡Œæƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {imported_count:,} ä»¶")
                
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.conn.rollback()
        
        return imported_count

    def import_holder_data(self):
        """å›½éš›å•†æ¨™æ¨©è€…æƒ…å ±ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        file_path = self.tsv_dir / self.tsv_files["holder"]
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º: {file_path}")
            return 0
        
        print(f"\nğŸ“¥ å›½éš›å•†æ¨™æ¨©è€…æƒ…å ±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {file_path.name}")
        
        cursor = self.conn.cursor()
        imported_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f, delimiter='\t')
                headers = next(reader)
                
                expected_cols = len(self.column_mappings["holder"])
                
                for row in reader:
                    if len(row) < expected_cols:
                        row_data = row + [None] * (expected_cols - len(row))
                    else:
                        row_data = row[:expected_cols]
                    
                    placeholders = ', '.join(['?'] * expected_cols)
                    sql = f"""
                    INSERT OR REPLACE INTO intl_trademark_holder 
                    ({', '.join(self.column_mappings["holder"])})
                    VALUES ({placeholders})
                    """
                    
                    cursor.execute(sql, row_data)
                    imported_count += 1
                    
                    if imported_count % 500 == 0:
                        print(f"   é€²è¡Œä¸­: {imported_count:,} ä»¶")
                        self.conn.commit()
                
                self.conn.commit()
                print(f"âœ… æ¨©è€…æƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {imported_count:,} ä»¶")
                
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.conn.rollback()
        
        return imported_count

    def import_goods_services_data(self):
        """å›½éš›å•†æ¨™æŒ‡å®šå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æƒ…å ±ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        file_path = self.tsv_dir / self.tsv_files["goods_services"]
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º: {file_path}")
            return 0
        
        print(f"\nğŸ“¥ å›½éš›å•†æ¨™æŒ‡å®šå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æƒ…å ±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {file_path.name}")
        
        cursor = self.conn.cursor()
        imported_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f, delimiter='\t')
                headers = next(reader)
                
                expected_cols = len(self.column_mappings["goods_services"])
                
                for row in reader:
                    if len(row) < expected_cols:
                        row_data = row + [None] * (expected_cols - len(row))
                    else:
                        row_data = row[:expected_cols]
                    
                    placeholders = ', '.join(['?'] * expected_cols)
                    sql = f"""
                    INSERT OR REPLACE INTO intl_trademark_goods_services 
                    ({', '.join(self.column_mappings["goods_services"])})
                    VALUES ({placeholders})
                    """
                    
                    cursor.execute(sql, row_data)
                    imported_count += 1
                    
                    if imported_count % 500 == 0:
                        print(f"   é€²è¡Œä¸­: {imported_count:,} ä»¶")
                        self.conn.commit()
                
                self.conn.commit()
                print(f"âœ… æŒ‡å®šå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {imported_count:,} ä»¶")
                
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.conn.rollback()
        
        return imported_count

    def import_trademark_text_data(self):
        """å›½éš›å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        file_path = self.tsv_dir / self.tsv_files["trademark_text"]
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º: {file_path}")
            return 0
        
        print(f"\nğŸ“¥ å›½éš›å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {file_path.name}")
        
        cursor = self.conn.cursor()
        imported_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f, delimiter='\t')
                headers = next(reader)
                
                expected_cols = len(self.column_mappings["trademark_text"])
                
                for row in reader:
                    if len(row) < expected_cols:
                        row_data = row + [None] * (expected_cols - len(row))
                    else:
                        row_data = row[:expected_cols]
                    
                    placeholders = ', '.join(['?'] * expected_cols)
                    sql = f"""
                    INSERT OR REPLACE INTO intl_trademark_text 
                    ({', '.join(self.column_mappings["trademark_text"])})
                    VALUES ({placeholders})
                    """
                    
                    cursor.execute(sql, row_data)
                    imported_count += 1
                    
                    if imported_count % 500 == 0:
                        print(f"   é€²è¡Œä¸­: {imported_count:,} ä»¶")
                        self.conn.commit()
                
                self.conn.commit()
                print(f"âœ… å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {imported_count:,} ä»¶")
                
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.conn.rollback()
        
        return imported_count

    def verify_import(self):
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœã®æ¤œè¨¼"""
        print(f"\nğŸ” Phase 2ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœæ¤œè¨¼")
        print("=" * 50)
        
        cursor = self.conn.cursor()
        
        tables = [
            ("intl_trademark_registration", "å›½éš›å•†æ¨™ç™»éŒ²ç®¡ç†"),
            ("intl_trademark_progress", "å›½éš›å•†æ¨™é€²è¡Œæƒ…å ±"),
            ("intl_trademark_holder", "å›½éš›å•†æ¨™æ¨©è€…æƒ…å ±"),
            ("intl_trademark_goods_services", "å›½éš›å•†æ¨™æŒ‡å®šå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹"),
            ("intl_trademark_text", "å›½éš›å•†æ¨™ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±")
        ]
        
        total_records = 0
        
        for table_name, description in tables:
            try:
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                count = cursor.fetchone()[0]
                total_records += count
                print(f"ğŸ“Š {description}: {count:,} ä»¶")
                
                # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                if count > 0:
                    cursor.execute(f"SELECT * FROM {table_name} LIMIT 1")
                    sample = cursor.fetchone()
                    if sample and 'intl_reg_num' in sample.keys():
                        print(f"   ã‚µãƒ³ãƒ—ãƒ«å›½éš›ç™»éŒ²ç•ªå·: {sample['intl_reg_num']}")
                
            except Exception as e:
                print(f"âŒ {description}ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"\nğŸ“ˆ Phase 2ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,} ä»¶")
        
        # æ¤œç´¢ãƒ“ãƒ¥ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        try:
            cursor.execute("SELECT COUNT(*) FROM intl_trademark_search_view")
            view_count = cursor.fetchone()[0]
            print(f"ğŸ” æ¤œç´¢å¯èƒ½ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {view_count:,} ä»¶")
            
            if view_count > 0:
                cursor.execute("""
                    SELECT intl_reg_num, trademark_text, goods_classes 
                    FROM intl_trademark_search_view 
                    LIMIT 3
                """)
                samples = cursor.fetchall()
                print(f"ğŸ“ æ¤œç´¢ãƒ“ãƒ¥ãƒ¼ã‚µãƒ³ãƒ—ãƒ«:")
                for sample in samples:
                    print(f"   {sample['intl_reg_num']}: {sample['trademark_text'][:50] if sample['trademark_text'] else 'ãªã—'}...")
        
        except Exception as e:
            print(f"âŒ æ¤œç´¢ãƒ“ãƒ¥ãƒ¼ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")

    def run_full_import(self):
        """å®Œå…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ"""
        print("ğŸš€ Phase 2: å›½éš›å•†æ¨™ãƒ‡ãƒ¼ã‚¿å®Œå…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹")
        print("=" * 60)
        
        start_time = datetime.now()
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            self.connect_db()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            self.create_tables()
            
            # å„TSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
            for data_type, filename in self.tsv_files.items():
                file_path = self.tsv_dir / filename
                if file_path.exists():
                    self.analyze_tsv_file(file_path)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            total_imported = 0
            total_imported += self.import_registration_data()
            total_imported += self.import_progress_data()
            total_imported += self.import_holder_data()
            total_imported += self.import_goods_services_data()
            total_imported += self.import_trademark_text_data()
            
            # çµæœæ¤œè¨¼
            self.verify_import()
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            print(f"\nâœ… Phase 2ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†!")
            print(f"ğŸ“Š ç·ã‚¤ãƒ³ãƒãƒ¼ãƒˆä»¶æ•°: {total_imported:,} ä»¶")
            print(f"â±ï¸  å‡¦ç†æ™‚é–“: {duration}")
            
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
            if self.conn:
                self.conn.rollback()
            return False
        
        finally:
            if self.conn:
                self.conn.close()
        
        return True

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    if len(sys.argv) > 1:
        if sys.argv[1] == "analyze":
            # åˆ†æã®ã¿å®Ÿè¡Œ
            importer = InternationalTrademarkImporter()
            importer.connect_db()
            
            for data_type, filename in importer.tsv_files.items():
                file_path = importer.tsv_dir / filename
                if file_path.exists():
                    importer.analyze_tsv_file(file_path)
            
            importer.conn.close()
            return
    
    # å®Œå…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
    importer = InternationalTrademarkImporter()
    success = importer.run_full_import()
    
    if success:
        print("\nğŸ‰ Phase 2å›½éš›å•†æ¨™ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   1. python3 cli_trademark_search.py --help ã§CLIæ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆ")
        print("   2. python3 app_dynamic_join_claude_optimized.py ã§Webã‚¢ãƒ—ãƒªã‚’èµ·å‹•")
        print("   3. å›½éš›å•†æ¨™ãƒ‡ãƒ¼ã‚¿ã®æ¤œç´¢æ©Ÿèƒ½ã‚’çµ±åˆ")
    else:
        print("\nâŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()