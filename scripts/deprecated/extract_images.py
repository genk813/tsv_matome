#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import base64
import imghdr
import re
from pathlib import Path
from collections import defaultdict

# è¨­å®š
ROOT = Path("C:/Users/ygenk/Desktop/tsv_matome")
TSV_FILE = ROOT / "tsv" / "upd_t_sample.tsv"
FINAL_DIR = ROOT / "images" / "final_complete"
FINAL_DIR.mkdir(exist_ok=True)

# çµ±è¨ˆç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
stats = {
    'total_rows': 0,
    'unique_app_nums': 0,
    'multirow_cases': 0,
    'skipped_empty': 0,
    'skipped_standard_char': 0,
    'skipped_invalid_base64': 0,
    'skipped_small_size': 0,
    'skipped_unknown_format': 0,
    'saved_successfully': 0,
    'fixed_images': 0,
    'recovered_unknown': 0,
    'errors': 0
}

def clean_base64_data(b64_data: str) -> str:
    """Base64ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã‚ˆã‚Šç©æ¥µçš„ï¼‰"""
    if not b64_data:
        return ""
    
    b64_data = b64_data.strip()
    
    # ãƒ‡ãƒ¼ã‚¿URLãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆã¯é™¤å»
    if ',' in b64_data and b64_data.startswith('data:'):
        b64_data = b64_data.split(',', 1)[1]
    
    # æ”¹è¡Œã€ç©ºç™½ã€ã‚¿ãƒ–ã‚’é™¤å»
    b64_data = re.sub(r'[\r\n\s\t]+', '', b64_data)
    
    # ç„¡åŠ¹ãªBase64æ–‡å­—ã‚’é™¤å»ï¼ˆã‚ˆã‚Šç©æ¥µçš„ï¼‰
    b64_data = re.sub(r'[^A-Za-z0-9+/=]', '', b64_data)
    
    # Base64ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®ä¿®æ­£
    missing_padding = len(b64_data) % 4
    if missing_padding:
        b64_data += '=' * (4 - missing_padding)
    
    return b64_data

def detect_image_format(img_bytes: bytes) -> str:
    """ç”»åƒå½¢å¼ã‚’æ¤œå‡ºï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰"""
    if len(img_bytes) < 8:
        return None
    
    # imghdirã‚’ä½¿ç”¨
    try:
        format_type = imghdr.what(None, img_bytes)
        if format_type:
            return format_type
    except:
        pass
    
    # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã«ã‚ˆã‚‹è©³ç´°åˆ¤å®š
    if img_bytes.startswith(b'\xFF\xD8\xFF'):
        return 'jpeg'
    elif img_bytes.startswith(b'\x89PNG\r\n\x1a\n'):
        return 'png'
    elif img_bytes.startswith(b'GIF87a') or img_bytes.startswith(b'GIF89a'):
        return 'gif'
    elif img_bytes.startswith(b'RIFF') and len(img_bytes) >= 12:
        if b'WEBP' in img_bytes[8:12]:
            return 'webp'
    elif img_bytes.startswith(b'BM'):
        return 'bmp'
    elif len(img_bytes) >= 12:
        # TIFFå½¢å¼
        if img_bytes.startswith(b'II\x2A\x00') or img_bytes.startswith(b'MM\x00\x2A'):
            return 'tiff'
    
    return None

def try_fix_image(img_bytes: bytes, img_format: str) -> bytes:
    """ç”»åƒã®ä¿®å¾©ã‚’è©¦è¡Œï¼ˆã‚ˆã‚Šç©æ¥µçš„ï¼‰"""
    try:
        if img_format == 'jpeg':
            # JPEGã®å ´åˆã€SOIç¢ºèªã¨EOIè¿½åŠ 
            if img_bytes.startswith(b'\xFF\xD8'):
                if not img_bytes.endswith(b'\xFF\xD9'):
                    stats['fixed_images'] += 1
                    return img_bytes + b'\xFF\xD9'
        elif img_format == 'png':
            # PNGã®å ´åˆã€IENDãƒãƒ£ãƒ³ã‚¯è¿½åŠ 
            if not img_bytes.endswith(b'IEND\xae\x42\x60\x82'):
                stats['fixed_images'] += 1
                return img_bytes + b'\x00\x00\x00\x00IEND\xae\x42\x60\x82'
        elif img_format == 'gif':
            # GIFã®å ´åˆã€ã‚¿ãƒ¼ãƒŸãƒãƒ¼ã‚¿ãƒ¼è¿½åŠ 
            if not img_bytes.endswith(b'\x3B'):
                stats['fixed_images'] += 1
                return img_bytes + b'\x3B'
        elif img_format == 'webp':
            # WebPã¯é€šå¸¸ä¿®å¾©ä¸è¦ã ãŒã€ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if len(img_bytes) >= 12:
                return img_bytes
        elif img_format == 'bmp':
            # BMPã®å ´åˆã€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºç¢ºèª
            if len(img_bytes) >= 54:  # æœ€å°BMPãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º
                return img_bytes
    except:
        pass
    
    return img_bytes

def try_recover_unknown_format(img_bytes: bytes) -> tuple:
    """ä¸æ˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ç”»åƒå¾©æ—§ã‚’è©¦è¡Œ"""
    if len(img_bytes) < 20:
        return None, None
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: å…ˆé ­ã«ã‚´ãƒŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
    for offset in range(0, min(200, len(img_bytes) - 10)):
        remaining = img_bytes[offset:]
        
        # JPEGæ¤œç´¢
        if remaining.startswith(b'\xFF\xD8\xFF'):
            stats['recovered_unknown'] += 1
            return 'jpeg', remaining
        # PNGæ¤œç´¢
        elif remaining.startswith(b'\x89PNG\r\n\x1a\n'):
            stats['recovered_unknown'] += 1
            return 'png', remaining
        # GIFæ¤œç´¢
        elif remaining.startswith(b'GIF87a') or remaining.startswith(b'GIF89a'):
            stats['recovered_unknown'] += 1
            return 'gif', remaining
        # BMPæ¤œç´¢
        elif remaining.startswith(b'BM'):
            stats['recovered_unknown'] += 1
            return 'bmp', remaining
    
    return None, None

def normalize_app_num(app_num: str) -> str:
    """å‡ºé¡˜ç•ªå·ã®æ­£è¦åŒ–"""
    if not app_num:
        return ""
    return app_num.replace("-", "").strip()

def is_standard_character_mark(b64_data: str) -> bool:
    """æ¨™æº–æ–‡å­—ã‹ã©ã†ã‹ã®åˆ¤å®šï¼ˆã‚ˆã‚Šå³å¯†ï¼‰"""
    if not b64_data:
        return True
    
    b64_data = b64_data.strip()
    
    # æ˜ç¢ºãªæ¨™æº–æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
    if (b64_data.startswith("//") or 
        set(b64_data.strip()) == {"/"} or 
        b64_data == "" or 
        b64_data.lower() in ["nan", "null", "none"] or 
        len(b64_data) < 20):
        return True
    
    # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ãŒå¤šã™ãã‚‹å ´åˆ
    if len(b64_data) > 0 and b64_data.count("/") / len(b64_data) > 0.8:
        return True
    
    # æ¨™æº–æ–‡å­—ã‚’ç¤ºã™æ–‡å­—åˆ—ã‚’å«ã‚€å ´åˆ
    if "æ¨™æº–æ–‡å­—" in b64_data or "standard" in b64_data.lower():
        return True
    
    return False

def consolidate_multirow_data(df: pd.DataFrame) -> dict:
    """è¤‡æ•°è¡Œã«ã‚ãŸã‚‹image_dataã‚’çµ±åˆï¼ˆè©³ç´°ç‰ˆï¼‰"""
    print("ğŸ”„ Consolidating multi-row image data...")
    
    # app_numã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆé †åºä¿æŒï¼‰
    grouped_data = defaultdict(list)
    
    for idx, row in df.iterrows():
        app_num = str(row.get("app_num", "")).strip()
        image_data = str(row.get("image_data", "")).strip()
        
        if app_num and image_data and image_data != 'nan':
            grouped_data[app_num].append(image_data)
    
    # çµ±åˆçµæœ
    consolidated = {}
    multirow_count = 0
    max_rows = 0
    
    for app_num, image_data_list in grouped_data.items():
        if len(image_data_list) > 1:
            # è¤‡æ•°è¡Œã®å ´åˆã€é€£çµ
            consolidated_data = ''.join(image_data_list)
            consolidated[app_num] = consolidated_data
            multirow_count += 1
            max_rows = max(max_rows, len(image_data_list))
            
            if multirow_count <= 20:  # æœ€åˆã®20ä»¶ã‚’ãƒ­ã‚°å‡ºåŠ›
                print(f"ğŸ“‹ Multi-row: {app_num} ({len(image_data_list)} rows, {len(consolidated_data):,} chars)")
        else:
            # å˜è¡Œã®å ´åˆã€ãã®ã¾ã¾
            consolidated[app_num] = image_data_list[0]
    
    stats['multirow_cases'] = multirow_count
    stats['unique_app_nums'] = len(consolidated)
    
    print(f"âœ“ Consolidated {multirow_count} multi-row cases")
    print(f"âœ“ Maximum rows per case: {max_rows}")
    print(f"âœ“ Total unique app_nums: {len(consolidated)}")
    
    return consolidated

def save_image(app_num: str, img_bytes: bytes, img_format: str) -> bool:
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
    try:
        normalized_app_num = normalize_app_num(app_num)
        
        extension_map = {
            'jpeg': 'jpg',
            'png': 'png', 
            'gif': 'gif',
            'webp': 'webp',
            'bmp': 'bmp',
            'tiff': 'tiff'
        }
        
        extension = extension_map.get(img_format, 'bin')
        out_path = FINAL_DIR / f"{normalized_app_num}.{extension}"
        
        with open(out_path, "wb") as f:
            f.write(img_bytes)
        
        return True
        
    except Exception as e:
        print(f"âœ— Failed to save {app_num}: {e}")
        return False

def process_final_extraction():
    """æœ€çµ‚çš„ãªç”»åƒæŠ½å‡ºå‡¦ç†"""
    print(f"ğŸ“ Reading TSV file: {TSV_FILE}")
    print(f"ğŸ’¾ Final output directory: {FINAL_DIR}")
    print("-" * 60)
    
    try:
        # TSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        df = pd.read_csv(TSV_FILE, sep="\t", encoding="cp932", dtype=str)
        print(f"âœ“ Successfully read file")
        
        stats['total_rows'] = len(df)
        print(f"ğŸ“Š Total rows: {stats['total_rows']}")
        
        # è¤‡æ•°è¡Œãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
        consolidated = consolidate_multirow_data(df)
        
        print(f"\nğŸ”¬ Processing consolidated image data...")
        success_count = 0
        large_images = 0
        
        for i, (app_num, b64_data) in enumerate(consolidated.items()):
            if i % 500 == 0:
                print(f"ğŸ“ˆ Processing {i:,} / {len(consolidated):,} (Success: {success_count}, Large: {large_images})")
            
            # æ¨™æº–æ–‡å­—ã®ã‚¹ã‚­ãƒƒãƒ—
            if is_standard_character_mark(b64_data):
                stats['skipped_standard_char'] += 1
                continue
            
            # Base64ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            cleaned_b64 = clean_base64_data(b64_data)
            if not cleaned_b64:
                stats['skipped_empty'] += 1
                continue
            
            try:
                # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                img_bytes = base64.b64decode(cleaned_b64, validate=True)
                
                # ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                if len(img_bytes) < 100:
                    stats['skipped_small_size'] += 1
                    continue
                
                # ç”»åƒå½¢å¼æ¤œå‡º
                img_format = detect_image_format(img_bytes)
                final_bytes = img_bytes
                
                # ä¸æ˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å ´åˆã€å¾©æ—§ã‚’è©¦è¡Œ
                if not img_format:
                    recovered_format, recovered_bytes = try_recover_unknown_format(img_bytes)
                    if recovered_format and recovered_bytes:
                        img_format = recovered_format
                        final_bytes = recovered_bytes
                
                if img_format:
                    # ä¿®å¾©ã‚’è©¦è¡Œ
                    final_bytes = try_fix_image(final_bytes, img_format)
                    
                    if save_image(app_num, final_bytes, img_format):
                        stats['saved_successfully'] += 1
                        success_count += 1
                        
                        # å¤§ããªç”»åƒã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                        if len(final_bytes) > 50000:
                            large_images += 1
                        
                        if i % 500 == 0 or len(final_bytes) > 100000:
                            print(f"âœ“ {app_num}.{img_format} ({len(final_bytes):,} bytes)")
                    else:
                        stats['errors'] += 1
                else:
                    stats['skipped_unknown_format'] += 1
                    
            except Exception as e:
                stats['skipped_invalid_base64'] += 1
                continue
    
    except Exception as e:
        print(f"âŒ Error reading TSV file: {e}")
        return
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š FINAL EXTRACTION RESULTS")
    print("=" * 60)
    print(f"Total rows in TSV:         {stats['total_rows']:,}")
    print(f"Unique app_nums:           {stats['unique_app_nums']:,}")
    print(f"Multi-row cases detected:  {stats['multirow_cases']:,}")
    print(f"Successfully saved:        {stats['saved_successfully']:,}")
    print(f"Large images (>50KB):      {large_images:,}")
    print(f"Fixed images:              {stats['fixed_images']:,}")
    print(f"Recovered from unknown:    {stats['recovered_unknown']:,}")
    print(f"Skipped (empty data):      {stats['skipped_empty']:,}")
    print(f"Skipped (standard char):   {stats['skipped_standard_char']:,}")
    print(f"Skipped (invalid base64):  {stats['skipped_invalid_base64']:,}")
    print(f"Skipped (too small):       {stats['skipped_small_size']:,}")
    print(f"Skipped (unknown format):  {stats['skipped_unknown_format']:,}")
    print(f"Errors:                    {stats['errors']:,}")
    
    success_rate = (stats['saved_successfully'] / stats['unique_app_nums'] * 100) if stats['unique_app_nums'] > 0 else 0
    print(f"\nâœ¨ Final success rate: {success_rate:.1f}%")
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ
    avg_per_multirow = stats['multirow_cases'] / max(1, stats['unique_app_nums'] - (stats['unique_app_nums'] - stats['multirow_cases']))
    print(f"ğŸ“Š Average rows per multi-row case: {avg_per_multirow:.1f}")
    
    if stats['saved_successfully'] > 0:
        print(f"\nâœ… Final images saved to: {FINAL_DIR}")
        print(f"ğŸ”§ Images repaired: {stats['fixed_images']}")
        print(f"ğŸ”„ Images recovered from unknown: {stats['recovered_unknown']}")
        print(f"ğŸ“ Large images (>50KB): {large_images:,}")
        
        print(f"\nğŸ‰ MISSION ACCOMPLISHED!")
        print(f"   From fragmented TSV data â†’ {stats['saved_successfully']:,} complete images")
        print(f"   Solved the multi-row puzzle! ğŸ§©")

if __name__ == "__main__":
    process_final_extraction()